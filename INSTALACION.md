# üöÄ Gu√≠a de Instalaci√≥n y Configuraci√≥n

## üìã Tabla de Contenidos

1. [Prerequisitos](#prerequisitos)
2. [Instalaci√≥n de Dependencias](#instalaci√≥n-de-dependencias)
3. [Configuraci√≥n del Entorno](#configuraci√≥n-del-entorno)
4. [Verificaci√≥n](#verificaci√≥n)
5. [Soluci√≥n de Problemas](#soluci√≥n-de-problemas)

---

## Prerequisitos

### Software Requerido

| Herramienta | Versi√≥n M√≠nima | Comando de Verificaci√≥n |
|-------------|----------------|-------------------------|
| Python | 3.8+ | `python --version` |
| pip | 20.0+ | `pip --version` |
| Google Cloud SDK | √öltimo | `gcloud --version` |
| Git | 2.0+ | `git --version` |

### Cuenta de Google Cloud Platform

- Cuenta de GCP activa con facturaci√≥n habilitada
- Permisos para crear recursos de Pub/Sub, Dataflow y BigQuery
- Proyecto de GCP creado

---

## Instalaci√≥n de Dependencias

### Paso 1: Crear Entorno Virtual (Recomendado)

```bash
# Crear entorno virtual
python -m venv venv

# Activar entorno virtual
# En macOS/Linux:
source venv/bin/activate

# En Windows:
venv\Scripts\activate
```

### Paso 2: Instalar Dependencias de Producci√≥n

```bash
# Instalar dependencias principales
pip install -r requirements.txt
```

Esto instalar√°:

- `apache-beam[gcp]==2.53.0` - Framework de procesamiento de datos
- `google-cloud-pubsub==2.18.4` - Cliente de Cloud Pub/Sub
- `google-cloud-bigquery==3.13.0` - Cliente de BigQuery
- `google-cloud-storage==2.13.0` - Cliente de Cloud Storage
- `python-dotenv==1.0.0` - Gesti√≥n de variables de entorno

### Paso 3: Instalar Dependencias de Desarrollo (Opcional)

```bash
# Instalar herramientas de desarrollo
pip install -r requirements-dev.txt
```

Esto instalar√°:

- `pytest==7.4.3` - Framework de testing
- `pytest-cov==4.1.0` - Cobertura de tests
- `black==23.11.0` - Formateador de c√≥digo
- `flake8==6.1.0` - Linter
- `mypy==1.7.1` - Type checker

---

## Configuraci√≥n del Entorno

### Paso 1: Crear Archivo de Configuraci√≥n

```bash
# Copiar el archivo de ejemplo
cp .env.example .env
```

### Paso 2: Editar Variables de Entorno

Abre el archivo `.env` y configura tus valores:

```bash
# Obligatorias
PROJECT_ID=tu-proyecto-gcp
REGION=us-central1
PUBSUB_TOPIC_ID=transactions-topic
BIGQUERY_DATASET_ID=streaming_data_warehouse_v2
BIGQUERY_TABLE_ID=transaction_aggregates

# Opcionales
WINDOW_SIZE_SECONDS=30
LOG_LEVEL=INFO
ENVIRONMENT=development
```

### Paso 3: Configurar Google Cloud SDK

```bash
# Autenticar con tu cuenta de Google
gcloud auth login

# Configurar proyecto por defecto
gcloud config set project tu-proyecto-gcp

# Configurar Application Default Credentials
gcloud auth application-default login
```

### Paso 4: Crear Recursos en BigQuery

```bash
# Ejecutar el script de configuraci√≥n
bash setup_bigquery.sh
```

Este script crear√°:

- Dataset de BigQuery
- Tabla con esquema optimizado
- Particionamiento por timestamp

---

## Verificaci√≥n

### 1. Verificar Instalaci√≥n de Python

```bash
python -c "import sys; print(f'Python {sys.version}')"
```

**Salida esperada:** `Python 3.8.x` o superior

### 2. Verificar Dependencias

```bash
# Verificar que todas las dependencias est√©n instaladas
pip list | grep -E "apache-beam|google-cloud|pytest|python-dotenv"
```

**Salida esperada:**

```text
apache-beam         2.53.0
google-cloud-bigquery 3.13.0
google-cloud-pubsub  2.18.4
google-cloud-storage 2.13.0
python-dotenv       1.0.0
pytest              7.4.3
```

### 3. Verificar Configuraci√≥n

```bash
# Ejecutar test de configuraci√≥n
python config.py
```

**Salida esperada:**

```text
‚úÖ Configuraci√≥n cargada exitosamente:
  PROJECT_ID: tu-proyecto-gcp
  REGION: us-central1
  PUBSUB_TOPIC_ID: transactions-topic
  ...
```

### 4. Ejecutar Tests Unitarios

```bash
# Ejecutar todos los tests
pytest test_pipeline.py -v

# Ejecutar con cobertura
pytest test_pipeline.py -v --cov=dataflow_pipeline --cov-report=term-missing
```

**Salida esperada:**

```text
test_pipeline.py::TestParseJson::test_parse_valid_json PASSED    [ 6%]
test_pipeline.py::TestParseJson::test_parse_invalid_json PASSED  [13%]
...
======== 15 passed in 2.34s ========
```

### 5. Verificar Conexi√≥n a GCP

```bash
# Listar proyectos disponibles
gcloud projects list

# Verificar credenciales
gcloud auth list
```

---

## Soluci√≥n de Problemas

### Error: "No module named 'dotenv'"

**Causa:** La librer√≠a `python-dotenv` no est√° instalada.

**Soluci√≥n:**

```bash
pip install python-dotenv==1.0.0
```

### Error: "No module named 'pytest'"

**Causa:** Pytest no est√° instalado.

**Soluci√≥n:**

```bash
pip install -r requirements-dev.txt
```

### Error: "No se ha podido resolver la importaci√≥n"

**Causa:** El entorno virtual no est√° activado o las dependencias no est√°n instaladas.

**Soluci√≥n:**

```bash
# 1. Activar entorno virtual
source venv/bin/activate  # macOS/Linux
# o
venv\Scripts\activate  # Windows

# 2. Reinstalar dependencias
pip install -r requirements.txt
```

### Error: "gcloud: command not found"

**Causa:** Google Cloud SDK no est√° instalado.

**Soluci√≥n:**

Instala Google Cloud SDK seg√∫n tu sistema operativo:

**macOS:**

```bash
brew install google-cloud-sdk
```

**Linux:**

```bash
curl https://sdk.cloud.google.com | bash
exec -l $SHELL
```

**Windows:**

Descarga el instalador desde: <https://cloud.google.com/sdk/docs/install>

### Error: "Permission Denied" en GCP

**Causa:** Faltan permisos en el proyecto de GCP.

**Soluci√≥n:**

Aseg√∫rate de tener los siguientes roles en tu cuenta:

- `Pub/Sub Editor` - Para crear topics y suscripciones
- `Dataflow Admin` - Para ejecutar pipelines
- `BigQuery Admin` - Para crear datasets y tablas
- `Storage Admin` - Para staging de Dataflow

```bash
# Verificar permisos
gcloud projects get-iam-policy tu-proyecto-gcp \
  --flatten="bindings[].members" \
  --filter="bindings.members:user:tu-email@example.com"
```

### Error: "MODULE_NOT_FOUND" en Dataflow

**Causa:** Dependencias no disponibles en workers de Dataflow.

**Soluci√≥n:**

Al ejecutar el pipeline de Dataflow, especifica el archivo de requisitos:

```bash
python dataflow_pipeline.py \
  --requirements_file=requirements.txt \
  --runner=DataflowRunner \
  --project=tu-proyecto-gcp \
  ...
```

### Warning: Tests con baja cobertura

**Causa:** Algunas l√≠neas de c√≥digo no est√°n cubiertas por tests.

**Soluci√≥n:**

```bash
# Ver reporte detallado de cobertura
pytest test_pipeline.py --cov=dataflow_pipeline --cov-report=html

# Abrir reporte HTML
open htmlcov/index.html  # macOS
xdg-open htmlcov/index.html  # Linux
```

---

## üéØ Checklist de Instalaci√≥n Completa

- [ ] Python 3.8+ instalado
- [ ] Entorno virtual creado y activado
- [ ] Dependencias de producci√≥n instaladas (`requirements.txt`)
- [ ] Dependencias de desarrollo instaladas (`requirements-dev.txt`)
- [ ] Google Cloud SDK instalado y configurado
- [ ] Archivo `.env` creado y configurado
- [ ] Credenciales de GCP autenticadas
- [ ] Script `setup_bigquery.sh` ejecutado exitosamente
- [ ] Test de configuraci√≥n (`python config.py`) exitoso
- [ ] Tests unitarios (`pytest test_pipeline.py -v`) pasando
- [ ] Verificaci√≥n de permisos en GCP completa

---

## üìö Pr√≥ximos Pasos

Una vez completada la instalaci√≥n:

1. **Desarrollo Local:**
   - Edita `publisher_simulator.py` para ajustar el simulador
   - Ejecuta tests despu√©s de cada cambio: `pytest test_pipeline.py -v`

2. **Despliegue en GCP:**
   - Revisa la [documentaci√≥n de despliegue](README.md#despliegue-en-dataflow)
   - Ejecuta el pipeline en modo DirectRunner primero
   - Despliega a DataflowRunner cuando est√© validado

3. **Monitoreo:**
   - Configura Cloud Monitoring
   - Revisa logs en Cloud Logging
   - Analiza m√©tricas en la consola de Dataflow

---

## üÜò Obtener Ayuda

Si encuentras problemas no listados aqu√≠:

1. **Revisa los logs:**

   ```bash
   # Logs del simulador
   tail -f logs/publisher.log
   
   # Logs de tests
   pytest test_pipeline.py -v --log-cli-level=DEBUG
   ```

2. **Consulta la documentaci√≥n oficial:**
   - [Apache Beam](https://beam.apache.org/documentation/)
   - [Cloud Dataflow](https://cloud.google.com/dataflow/docs)
   - [Cloud Pub/Sub](https://cloud.google.com/pubsub/docs)
   - [BigQuery](https://cloud.google.com/bigquery/docs)

3. **Recursos adicionales:**
   - [README.md](README.md) - Documentaci√≥n principal del proyecto
   - [MEJORAS_PROFESIONALES.md](MEJORAS_PROFESIONALES.md) - Detalles t√©cnicos de mejoras

---

**√öltima actualizaci√≥n:** 17 de Diciembre de 2025  
**Versi√≥n:** 2.0.0
