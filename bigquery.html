<!DOCTYPE html>
<html lang="es">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="description" content="BigQuery: Data Warehouse anal칤tico serverless para almacenamiento y an치lisis de datos en tiempo real.">
        <meta name="keywords" content="BigQuery, GCP, Data Warehouse, SQL, Streaming Inserts, Anal칤tica">
        <title>Detalle | BigQuery</title>
        <link rel="stylesheet" href="css/style.css">
    </head>
    <body>

        <header class="hero">
            <div class="container">
                <h1 class="project-title">Pipeline Serverless de Streaming en
                    GCP</h1>
                <p class="subtitle">An치lisis de Transacciones en Tiempo Real
                    (Latencia Baja)</p>
            </div>
        </header>

        <nav class="tool-nav">
            <div class="container">
                <a href="index.html" class="nav-item"
                    data-tool="overview">Visi칩n General</a>
                <a href="pubsub.html" class="nav-item" data-tool="pubsub">Cloud
                    Pub/Sub</a>
                <a href="dataflow.html" class="nav-item"
                    data-tool="dataflow">Cloud Dataflow</a>
                <a href="bigquery.html" class="nav-item active"
                    data-tool="bigquery">BigQuery</a>
                <a href="apachebeam.html" class="nav-item"
                    data-tool="apachebeam">Apache Beam (Python)</a>
            </div>
        </nav>

        <main class="container main-content">
            <section class="section tool-detail-content">
                <h2>BigQuery: Data Warehouse Anal칤tico y Destino Final</h2>
                <p>BigQuery es el servicio de *Data Warehouse* sin servidor
                    (serverless) de Google Cloud. Es altamente escalable y
                    optimizado para el an치lisis de petabytes de datos usando
                    consultas SQL. En este proyecto, act칰a como el destino final
                    de los datos procesados por Dataflow.</p>

                <h3>Rol en el Proyecto: Almacenamiento y Disponibilidad
                    Inmediata</h3>
                <p>Elegimos BigQuery porque es la mejor opci칩n para manejar las
                    <strong>inserciones de streaming</strong> de Dataflow y poner los datos a
                    disposici칩n inmediata para el an치lisis o visualizaci칩n (por
                    ejemplo, con Looker Studio).</p>

                <h3>Conceptos Clave Aplicados</h3>

                <div class="component-list">
                    <ul>
                        <li>
                            <h4>Inserci칩n de Streaming</h4>
                            <p>Se utiliz칩 el m칠todo de inserci칩n de *streaming*
                                (`method='STREAMING_INSERTS'`) en la fase de
                                escritura de Apache Beam. Esto permite que los
                                datos agregados por Dataflow (las ventanas de 30
                                segundos) est칠n disponibles en BigQuery **en
                                cuesti칩n de segundos**.</p>
                        </li>
                        <li>
                            <h4>Modelo Columnar y Particionamiento</h4>
                            <p>BigQuery es un almac칠n de datos columnar. Aunque
                                Dataflow inserta los datos, BigQuery est치
                                optimizado para la partici칩n autom치tica por la
                                columna de tiempo (`window_start_time`). Esto
                                garantiza que las consultas anal칤ticas sobre
                                per칤odos espec칤ficos sean **r치pidas y
                                econ칩micas**.</p>
                        </li>
                        <li>
                            <h4>Esquema y Validaci칩n</h4>
                            <p>Se defini칩 un esquema de tabla que solo incluye
                                los datos <strong>agregados</strong> (<code>total_transactions</code>,
                                <code>total_amount_sum</code>), asegurando que solo se
                                almacena informaci칩n limpia, concisa y lista
                                para ser analizada, optimizando el rendimiento
                                de las consultas.</p>
                        </li>
                    </ul>
                </div>

                <a href="https://cloud.google.com/bigquery" target="_blank" rel="noopener noreferrer"
                    class="official-link">Documentaci칩n Oficial de Google Cloud
                    BigQuery</a>
            </section>

            <!-- Quiz de Certificaci칩n -->
            <section class="section quiz-container">
                <h2 class="quiz-title">游닇 Quiz de Certificaci칩n: BigQuery</h2>
                <p class="quiz-intro">Pon a prueba tus conocimientos con preguntas tipo Professional Data Engineer</p>
                <div id="bigqueryQuiz"></div>
            </section>
        </main>

        <footer>
            <p>&copy; 2025 Eduardo Villena Lozano | Ingenier칤a de Datos</p>
        </footer>

        <script src="js/main.js"></script>
        <script src="js/quiz.js"></script>
        <script>
            // Preguntas espec칤ficas de BigQuery para Professional Data Engineer
            const bigqueryQuestions = [
                {
                    question: "Tu tabla de BigQuery con 5TB de datos tiene consultas lentas y costosas. La mayor칤a de las consultas filtran por 'fecha' y 'regi칩n'. 쮺u치l es la mejor estrategia de optimizaci칩n?",
                    options: [
                        "Crear 칤ndices en las columnas 'fecha' y 'regi칩n'",
                        "Usar particionamiento por 'fecha' y clustering por 'regi칩n'",
                        "Aumentar el n칰mero de slots reservados",
                        "Denormalizar todas las tablas relacionadas"
                    ],
                    correct: 1,
                    explanation: "BigQuery NO usa 칤ndices tradicionales. La mejor pr치ctica es: PARTICIONAR por fecha (limita el escaneo de particiones) y CLUSTERING por regi칩n (organiza datos f칤sicamente). Particionar reduce costos (solo escanea particiones necesarias) y clustering mejora rendimiento (datos relacionados est치n juntos). Ejemplo: si consultas datos del 칰ltimo mes en regi칩n 'US', BigQuery solo escanea esa partici칩n y salta bloques de otras regiones."
                },
                {
                    question: "Est치s cargando datos de streaming a BigQuery. 쮺u치l es la diferencia entre 'streaming inserts' y 'BigQuery Storage Write API'?",
                    options: [
                        "Storage Write API es m치s lento pero m치s barato",
                        "Streaming inserts tiene disponibilidad inmediata; Storage Write API tiene latencia pero es m치s eficiente",
                        "Storage Write API solo funciona con Dataflow",
                        "No hay diferencia, son sin칩nimos"
                    ],
                    correct: 1,
                    explanation: "STREAMING INSERTS: Disponibilidad INMEDIATA (consultas ven datos al instante), pero costo m치s alto ($0.010 por 200MB) y l칤mites de cuota m치s estrictos. STORAGE WRITE API: Latencia de hasta 90 segundos para disponibilidad, pero m치s eficiente, mejor throughput, y sin costos de streaming. Usa Storage Write API para cargas masivas o pipelines de alta frecuencia donde 90 segundos de latencia es aceptable. Usa streaming inserts para casos que requieren latencia sub-segundo."
                },
                {
                    question: "쮺u치l es la diferencia clave entre una tabla 'particionada' y una tabla 'clustered' en BigQuery?",
                    options: [
                        "Particionado divide la tabla en segmentos; Clustering ordena datos dentro de cada segmento",
                        "Particionado es para tablas grandes; Clustering es para tablas peque침as",
                        "Particionado reduce costos; Clustering reduce latencia (no hay overlap)",
                        "Son mutuamente exclusivos, solo puedes usar uno"
                    ],
                    correct: 0,
                    explanation: "PARTICIONADO: Divide la tabla en segmentos f칤sicos separados (por fecha, rango entero, etc.). BigQuery puede ELIMINAR particiones completas sin escanearlas (pruning), reduciendo costos. CLUSTERING: Ordena y organiza datos DENTRO de cada partici칩n por hasta 4 columnas. Mejora rendimiento pero NO garantiza eliminaci칩n de datos (best-effort pruning). MEJOR PR츼CTICA: Combinar ambos - particionar por columna de baja cardinalidad (fecha), clustering por columnas de filtros comunes (regi칩n, usuario, categor칤a)."
                },
                {
                    question: "Necesitas unir (JOIN) dos tablas grandes en BigQuery y la consulta es muy lenta. 쮺u치l es la t칠cnica de optimizaci칩n m치s efectiva?",
                    options: [
                        "Usar INNER JOIN en lugar de LEFT JOIN siempre",
                        "Filtrar datos lo antes posible ANTES del JOIN usando WHERE",
                        "Dividir el JOIN en m칰ltiples consultas m치s peque침as",
                        "Aumentar el n칰mero de workers en Dataflow"
                    ],
                    correct: 1,
                    explanation: "FILTRAR ANTES DEL JOIN es cr칤tico. BigQuery procesa JOINs despu칠s de leer datos, as칤 que si filtras con WHERE ANTES del JOIN, reduces dram치ticamente los datos procesados. Ejemplo: en lugar de 'FROM tabla1 JOIN tabla2 ON ... WHERE fecha > 2024', usa 'FROM (SELECT * FROM tabla1 WHERE fecha > 2024) JOIN (SELECT * FROM tabla2 WHERE fecha > 2024)'. Tambi칠n: asegura que est치s haciendo JOIN en columnas particionadas/clustered, y considera pre-agregar datos si es posible."
                },
                {
                    question: "쮺u치ndo deber칤as usar 'materialized views' en BigQuery en lugar de vistas normales?",
                    options: [
                        "Siempre, las materialized views son siempre m치s r치pidas",
                        "Cuando la consulta es compleja/costosa y los datos base cambian con poca frecuencia",
                        "Solo para tablas con menos de 1GB de datos",
                        "Nunca, son m치s caras sin beneficio real"
                    ],
                    correct: 1,
                    explanation: "Materialized views PRE-CALCULAN y ALMACENAN resultados de consultas complejas. Casos de uso ideales: 1) Agregaciones costosas consultadas frecuentemente, 2) JOINs complejos entre tablas grandes, 3) Datos base cambian ocasionalmente. BigQuery ACTUALIZA incrementalmente la materialized view cuando cambian datos base. COSTO: Pagas por almacenamiento de la view + actualizaciones incrementales. NO uses si: datos cambian constantemente (alto costo de actualizaci칩n), consulta es simple (overhead innecesario), o necesitas datos en tiempo real (puede haber lag de minutos)."
                },
                {
                    question: "Tu empresa tiene datos sensibles en BigQuery. 쮺u치l es la mejor estrategia para proteger informaci칩n personal (PII) en columnas espec칤ficas?",
                    options: [
                        "Usar encriptaci칩n a nivel de columna manualmente antes de insertar",
                        "Implementar Column-level Security con Policy Tags y Data Catalog",
                        "Crear vistas separadas sin las columnas sensibles para cada usuario",
                        "Usar row-level security para ocultar filas completas"
                    ],
                    correct: 1,
                    explanation: "COLUMN-LEVEL SECURITY con Policy Tags es la soluci칩n nativa y escalable: 1) Crea taxonom칤as en Data Catalog, 2) Aplica policy tags a columnas sensibles (email, SSN, etc.), 3) Usa IAM para controlar qui칠n puede ver cada policy tag. Los usuarios sin permisos ven NULL en esas columnas. VENTAJAS: Control granular, auditable, integrado con IAM, funciona con todas las herramientas de BigQuery. COMPLEMENTA con DLP API para detectar y clasificar PII autom치ticamente."
                },
                {
                    question: "쮺u치l es la diferencia entre 'on-demand pricing' y 'flat-rate pricing' en BigQuery?",
                    options: [
                        "On-demand es m치s barato siempre",
                        "On-demand cobra por TB escaneados; Flat-rate es capacidad reservada con costo fijo mensual",
                        "Flat-rate solo est치 disponible para enterprise customers",
                        "On-demand tiene mejor performance que flat-rate"
                    ],
                    correct: 1,
                    explanation: "ON-DEMAND: Pagas $5 por TB de datos escaneados (hasta $6.25 con an치lisis BI Engine). Bueno para workloads impredecibles o bajos vol칰menes. FLAT-RATE: Reservas slots (unidades de capacidad computacional) por $2,000/100 slots/mes (commitments de 1 a침o) o m치s con flex slots. CU츼NDO USAR FLAT-RATE: 1) Workloads predecibles y altos vol칰menes (break-even ~$10K/mes), 2) Necesitas performance predecible sin throttling, 3) M칰ltiples proyectos compartiendo capacidad. USA on-demand para empezar, migra a flat-rate al escalar."
                },
                {
                    question: "쯈u칠 es BigQuery BI Engine y cu치ndo deber칤as usarlo?",
                    options: [
                        "Un motor de ETL para transformar datos en BigQuery",
                        "Un servicio de caching en memoria para acelerar consultas de BI con baja latencia",
                        "Una herramienta de visualizaci칩n como Looker",
                        "Un engine alternativo m치s barato que el est치ndar"
                    ],
                    correct: 1,
                    explanation: "BI ENGINE es un servicio de caching IN-MEMORY que acelera consultas interactivas de dashboards. BENEFICIOS: 1) Latencia sub-segundo para consultas repetitivas, 2) Reduce costos (consultas cacheadas no se cobran), 3) Integraci칩n autom치tica con Looker, Data Studio, etc. CU츼NDO USAR: Dashboards interactivos con usuarios concurrentes consultando los mismos datos agregados. LIMITACIONES: Solo cachea agregaciones/queries compatibles (no todas), requiere reservar capacidad en GB de RAM ($0.048 por GB/hora). Complementa, no reemplaza optimizaciones de tablas."
                },
                {
                    question: "쮺u치l es la mejor pr치ctica para exportar grandes vol칰menes de datos (>1TB) desde BigQuery a Cloud Storage?",
                    options: [
                        "Usar la UI de BigQuery para export directo",
                        "Usar EXPORT DATA en SQL con wildcard para generar m칰ltiples archivos particionados",
                        "Ejecutar consultas y guardar resultados manualmente",
                        "Usar bq command-line tool con un solo archivo de output"
                    ],
                    correct: 1,
                    explanation: "Para exports grandes usa EXPORT DATA con wildcards: EXPORT DATA OPTIONS(uri='gs://bucket/prefix-*.json', format='JSON') AS SELECT * FROM tabla. IMPORTANTES: 1) Usa WILDCARD (*) para generar m칰ltiples archivos en paralelo (m치s r치pido), 2) BigQuery limita archivos individuales a 1GB, el wildcard lo maneja autom치ticamente, 3) Considera comprimir (compression='GZIP'), 4) Para Avro/Parquet (mejores para analytics) en lugar de JSON/CSV. ALTERNATIVA: Usa Dataflow para procesamiento y export simult치neo."
                },
                {
                    question: "Necesitas unir una tabla grande (1TB) con una tabla peque침a (100MB) frecuentemente. 쮺u치l es la mejor optimizaci칩n?",
                    options: [
                        "Crear un JOIN pre-calculado en una tabla separada",
                        "Usar BROADCAST JOIN hint para la tabla peque침a",
                        "Denormalizar completamente ambas tablas",
                        "Crear 칤ndices en las columnas de join"
                    ],
                    correct: 1,
                    explanation: "Usa /* @hints BROADCAST(small_table) */ para forzar un BROADCAST JOIN. BigQuery copia la tabla peque침a a todos los workers, evitando shuffle de la tabla grande. Esto es DRAM츼TICAMENTE m치s eficiente. EJEMPLO: SELECT * FROM large_table JOIN /* @hints BROADCAST(small_table) */ small_table ON ... CU츼NDO: Tabla peque침a < 10GB, Join frecuente. BigQuery a veces lo hace autom치ticamente, pero el hint lo garantiza. NO USES si ambas tablas son grandes (broadcast ser칤a costoso)."
                }
            ];

            document.addEventListener('DOMContentLoaded', () => {
                new Quiz('bigqueryQuiz', bigqueryQuestions);
            });
        </script>
    </body>
</html>