# üìö Historial de Desarrollo del Proyecto

**Proyecto**: Pipeline Serverless de Streaming en GCP - Proyecto Educativo  
**Autor**: Eduardo Villena Lozano  
**Fecha**: 17 de diciembre de 2025  
**Repositorio**: <https://github.com/Edushuaia/streaming-serverless-pipeline>

---

## üéØ Resumen Ejecutivo

Este documento registra el proceso completo de transformaci√≥n de un prototipo de pipeline de streaming en un proyecto profesional, educativo y listo para portfolio. El proyecto evolucion√≥ desde una versi√≥n b√°sica hasta una implementaci√≥n completa con:

- ‚úÖ 10 mejoras profesionales implementadas
- ‚úÖ Apache Beam 2.70.0 ARM64 nativo instalado
- ‚úÖ 14 tests unitarios (66% cobertura)
- ‚úÖ Sitio web interactivo con galer√≠a de evidencias
- ‚úÖ Quiz educativo con 40 preguntas
- ‚úÖ Infraestructura GCP desplegada y probada
- ‚úÖ Enfoque educativo cient√≠fico-tecnol√≥gico
- ‚úÖ Publicado en GitHub y preparado para LinkedIn

---

## üìÖ Cronolog√≠a Detallada

### **Fase 1: Revisi√≥n Inicial y Planificaci√≥n**

**Objetivo**: Evaluar el estado inicial del proyecto y planificar mejoras

**Acciones realizadas**:

- Revisi√≥n completa de la estructura del proyecto
- Identificaci√≥n de √°reas de mejora
- Definici√≥n de 10 mejoras profesionales prioritarias

### **Fase 2: Implementaci√≥n de Mejoras Profesionales**

**Objetivo**: Transformar el prototipo en un proyecto production-ready

**Mejoras Implementadas**:

1. **Configuraci√≥n centralizada** (`config.py`)
   - Variables de entorno con python-dotenv
   - Valores por defecto seguros
   - Validaci√≥n de configuraci√≥n

2. **Logging estructurado**
   - Configuraci√≥n en `logging_config.py`
   - Niveles: DEBUG, INFO, WARNING, ERROR
   - Formato consistente con timestamps

3. **Tests unitarios** (`tests/test_pipeline.py`)
   - 14 tests con pytest
   - 66% de cobertura de c√≥digo
   - Tests para funciones de agregaci√≥n y parsing

4. **Requirements.txt actualizado**
   - Versiones espec√≠ficas y compatibles
   - Apache Beam con dependencias GCP
   - Herramientas de desarrollo (pytest, pytest-cov)

5. **Documentaci√≥n mejorada** (README.md)
   - Badges profesionales
   - Diagramas de arquitectura
   - Instrucciones de instalaci√≥n y despliegue
   - Tabla de servicios con justificaciones

6. **.gitignore profesional**
   - Exclusi√≥n de credenciales (.env)
   - Archivos temporales de Python
   - Directorios de cach√© y virtualenv

7. **Manejo robusto de errores**
   - Try-except en funciones cr√≠ticas
   - Logging de errores con contexto
   - Recuperaci√≥n graciosa de fallos

8. **Schema mejorado de BigQuery**
   - Tipos de datos correctos (INT64, FLOAT64)
   - Particionamiento por timestamp
   - Campos opcionales bien definidos

9. **Publisher mejorado** (`publisher_simulator.py`)
   - Estad√≠sticas en tiempo real
   - Control de tasa de mensajes
   - Manejo de se√±ales (Ctrl+C)

10. **Estructura de carpetas profesional**
    - `tests/` para testing
    - `css/`, `js/`, `img/` para frontend
    - Separaci√≥n de concerns

**Resultado**: Proyecto con estructura profesional y c√≥digo production-ready.

---

### **Fase 3: Correcci√≥n de Linting y Formato**

**Objetivo**: Mantener calidad y consistencia del c√≥digo seg√∫n est√°ndares profesionales

**Archivos corregidos**:

- `README.md`: 34 errores ‚Üí 0 errores
- `ARCHITECTURE.md`: 23 errores ‚Üí 0 errores
- `TESTING.md`: 9 errores ‚Üí 0 errores
- `DEPLOYMENT.md`: 18 errores ‚Üí 0 errores

**Tipos de errores corregidos**:

- MD022: Espacios alrededor de encabezados
- MD024: Encabezados duplicados
- MD031: Bloques de c√≥digo con espacios
- MD032: Listas con espacios
- MD034: URLs sin formato
- MD036: √ânfasis en lugar de encabezados
- MD040: Bloques de c√≥digo sin lenguaje

**Resultado**: 0 errores de linting, c√≥digo limpio y profesional.

---

### **Fase 4: Instalaci√≥n de Apache Beam 2.70.0**

**Objetivo**: Configurar entorno de desarrollo con Apache Beam en arquitectura ARM64

**Desaf√≠o**: Mac mini con Apple Silicon (ARM64) requer√≠a instalaci√≥n nativa

**Proceso**:

1. **Verificaci√≥n de arquitectura**:

   ```bash
   arch
   # arm64

   ```

2. **Instalaci√≥n ARM64 nativa**:

   ```bash
   arch -arm64 python3 -m pip install --upgrade --force-reinstall apache-beam[gcp]==2.70.0

   ```

3. **Verificaci√≥n**:

   ```python
   import apache_beam as beam
   print(beam.__version__)
   # 2.70.0

   ```

**Notas t√©cnicas**:

- Python 3.13.7 Universal Binary corriendo en modo ARM64
- Apache Beam 2.70.0 con soporte nativo para Apple Silicon
- Dependencias GCP incluidas

**Resultado**: Apache Beam funcional en arquitectura ARM64.

---

### **Fase 5: Testing y Validaci√≥n**

**Objetivo**: Implementar suite de tests completa y medir cobertura de c√≥digo

**Comando ejecutado**:

```bash
pytest --cov=dataflow_pipeline --cov-report=term tests/ -v

```

**Resultados**:

- ‚úÖ 14 tests pasados
- ‚úÖ 66% de cobertura de c√≥digo
- ‚úÖ Tiempo de ejecuci√≥n: 2.71s

**Tests implementados**:

1. `test_parse_json_valid` - Parsing de JSON v√°lido
2. `test_parse_json_invalid` - Manejo de JSON inv√°lido
3. `test_parse_json_missing_fields` - Campos faltantes
4. `test_aggregate_transactions_single` - Agregaci√≥n √∫nica
5. `test_aggregate_transactions_multiple` - Agregaci√≥n m√∫ltiple
6. `test_aggregate_transactions_empty` - Lista vac√≠a
7. `test_format_for_bigquery` - Formateo para BigQuery
8. `test_format_for_bigquery_types` - Tipos de datos correctos
9. Y m√°s...

**Resultado**: Suite de tests completa y funcionando.

---

### **Fase 6: Optimizaci√≥n del Sitio Web**

**Objetivo**: Mejorar UX y reducir espacio vertical del header

**Mejoras implementadas**:

1. **Reducci√≥n del header** (40% m√°s compacto):
   - Hero: 500px ‚Üí 300px
   - Project title: 3.5em ‚Üí 2.5em
   - Subtitle: 1.5em ‚Üí 1.2em

2. **Eliminaci√≥n de navegaci√≥n redundante**:
   - Removida barra de navegaci√≥n duplicada
   - Mantenidos badges interactivos en hero

3. **Optimizaci√≥n visual**:
   - Espaciado reducido
   - Mejor uso del espacio vertical
   - UX m√°s limpia

**Resultado**: Sitio web m√°s profesional y f√°cil de navegar.

---

### **Fase 7: Sistema de Quiz Interactivo**

**Objetivo**: Agregar valor educativo con preguntas tipo certificaci√≥n Professional Data Engineer

**Implementaci√≥n**:

**Archivo creado**: `js/quiz.js` (569 l√≠neas)

**Caracter√≠sticas**:

- 40 preguntas de certificaci√≥n
- 4 p√°ginas con 10 preguntas cada una:
  - `pubsub.html`: Cloud Pub/Sub
  - `dataflow.html`: Cloud Dataflow
  - `apachebeam.html`: Apache Beam
  - `bigquery.html`: BigQuery
- Feedback inmediato
- Contador de progreso
- Dise√±o responsivo

**Ejemplo de pregunta**:

```javascript
{
    question: "¬øCu√°l es la principal ventaja de usar Cloud Pub/Sub en arquitecturas serverless?",
    options: [
        "Almacenamiento permanente de datos",
        "Desacoplamiento entre productores y consumidores",
        "An√°lisis SQL en tiempo real",
        "Procesamiento de ventanas temporales"
    ],
    correct: 1,
    explanation: "Cloud Pub/Sub desacopla productores y consumidores..."
}

```

**Resultado**: Sistema educativo interactivo implementado.

---

### **Fase 8: Gu√≠a de Despliegue en GCP**

**Objetivo**: Documentar proceso completo de despliegue paso a paso para replicabilidad

**Archivo creado**: `GUIA_CAPTURAS.md` (391 l√≠neas)

**Estructura**:

- 8 fases de despliegue
- 14 capturas de pantalla a tomar
- Comandos espec√≠ficos con explicaciones
- Checklist completo

**Fases**:

1. Preparaci√≥n (entorno, credenciales)
2. Infraestructura (Pub/Sub, BigQuery, Storage)
3. Pipeline (despliegue de Dataflow)
4. Publicar mensajes (publisher)
5. Resultados (verificaci√≥n BigQuery)
6. M√©tricas (monitoreo)
7. Testing (ejecuci√≥n local)
8. Capturas web (sitio interactivo)

**Resultado**: Gu√≠a completa para despliegue paso a paso.

---

### **Fase 9: Despliegue en GCP**

**Objetivo**: Desplegar infraestructura completa y validar funcionamiento end-to-end

**Comandos ejecutados**:

1. **Verificaci√≥n de proyecto**:

   ```bash
   gcloud config get-value project
   # streaming-serverless-dataflow

   ```

2. **Habilitaci√≥n de APIs**:

   ```bash
   gcloud services enable pubsub.googleapis.com
   gcloud services enable bigquery.googleapis.com
   gcloud services enable storage.googleapis.com
   gcloud services enable dataflow.googleapis.com
   gcloud services enable compute.googleapis.com

   ```

3. **Creaci√≥n de Topic Pub/Sub**:

   ```bash
   gcloud pubsub topics create transactions-topic
   gcloud pubsub subscriptions create dataflow-subscription \
       --topic=transactions-topic

   ```

4. **Creaci√≥n de BigQuery Dataset y Tabla**:

   ```bash
   bash setup_bigquery.sh

   ```

   **Problema**: Error con schema (INTEGER/FLOAT no reconocidos, TIMESTAMP:REQUIRED incompatible)

   **Soluci√≥n**: Actualizaci√≥n del schema:

   - `INTEGER` ‚Üí `INT64`
   - `FLOAT` ‚Üí `FLOAT64`
   - Removido `:REQUIRED` de `window_start_time`

5. **Creaci√≥n de Cloud Storage Bucket**:

   ```bash
   gsutil mb -l us-central1 gs://streaming-serverless-dataflow-staging

   ```

6. **Despliegue del Pipeline Dataflow**:

   ```bash
   python dataflow_pipeline.py \
       --runner=DataflowRunner \
       --project=streaming-serverless-dataflow \
       --region=us-central1 \
       --temp_location=gs://streaming-serverless-dataflow-staging/temp \
       --staging_location=gs://streaming-serverless-dataflow-staging/staging

   ```

   **Job ID**: `beamapp-ashramsatcitananda-1217173344-235534-vzxudzud`

   **Estado**: RUNNING (posteriormente cancelado para evitar costos)

7. **Publicaci√≥n de mensajes de prueba**:

   ```bash
   python publisher_simulator.py

   ```

   **Estad√≠sticas**:

   - Mensajes enviados: 23,360+
   - Duraci√≥n: ~4.3 horas
   - Tasa promedio: 1.47 msg/s
   - Errores: 1 (99.996% √©xito)

**Recursos creados**:

- ‚úÖ Cloud Pub/Sub: `transactions-topic` + `dataflow-subscription`
- ‚úÖ BigQuery: `streaming_data_warehouse_v2` dataset + `transaction_aggregates` table
- ‚úÖ Cloud Storage: `gs://streaming-serverless-dataflow-staging`
- ‚úÖ Dataflow: Job ejecutado y posteriormente cancelado

**Resultado**: Infraestructura completa desplegada y probada.

---

### **Fase 10: Galer√≠a de Evidencias**

**Objetivo**: Crear galer√≠a visual interactiva que documente el proyecto funcionando

**Archivo creado**: `evidencias.html` (602 l√≠neas)

**Caracter√≠sticas**:

1. **9 tarjetas de evidencias**:
   - Infraestructura (3): Pub/Sub, BigQuery, Storage
   - Pipeline (2): Grafo, M√©tricas
   - Resultados (2): Datos, M√©tricas Pub/Sub
   - Testing (2): Tests, Cobertura

2. **Lightbox interactivo**:
   - Click en imagen para ampliar
   - Navegaci√≥n con flechas (‚Üê ‚Üí)
   - Cierre con ESC
   - Contador de im√°genes

3. **Navegaci√≥n flotante**:
   - Botones laterales con tooltips
   - Enlaces a secciones (üè†üìä‚öôÔ∏èüß™)
   - Scroll suave

4. **Bot√≥n scroll-to-top**:
   - Aparece despu√©s de 300px
   - Animaci√≥n suave

5. **Estad√≠sticas destacadas**:
   - 9 capturas
   - 320+ mensajes procesados
   - 14/14 tests pasados
   - 66% cobertura

**Screenshots capturados**:

1. `evidencia-01-pubsub.png` - Cloud Pub/Sub Topic
2. `evidencia-02-bigquery.png` - BigQuery Dataset
3. `evidencia-03-storage.png` - Cloud Storage Bucket
4. `evidencia-04-dataflow-graph.png` - Grafo del Pipeline
5. `evidencia-05-dataflow-metrics.png` - M√©tricas Dataflow
6. `evidencia-06-bigquery-results.png` - Resultados BigQuery
7. `evidencia-07-pubsub-metrics.png` - M√©tricas Pub/Sub
8. `evidencia-08-tests-coverage.png` - Suite de Tests
9. `evidencia-09-coverage-report.png` - Reporte HTML

**Resultado**: Galer√≠a profesional con todas las evidencias.

---

### **Fase 11: Mejoras Visuales de la Galer√≠a**

**Objetivo**: Agregar animaciones y efectos visuales profesionales a la galer√≠a

**Mejoras implementadas**:

1. **Efecto zoom en im√°genes**:
   - Transici√≥n suave 0.4s
   - Scale 1.05 al hover

   ```css
   .evidencia-image:hover {
       transform: scale(1.05);
   }

   ```

2. **Badges tecnol√≥gicos animados**:
   - 8 badges con iconos
   - Animaci√≥n fadeInUp escalonada
   - Hover con elevaci√≥n y sombra
   - Tecnolog√≠as: GCP, Pub/Sub, Dataflow, Beam, BigQuery, Python, pytest, Storage

3. **Bot√≥n GitHub destacado**:
   - Gradiente negro (#24292e ‚Üí #000000)
   - Logo SVG de GitHub
   - Hover con elevaci√≥n
   - Enlace directo al repositorio

**C√≥digo agregado**: ~150 l√≠neas CSS + HTML

**Resultado**: UX mejorada con animaciones profesionales.

---

### **Fase 12: Publicaci√≥n en GitHub**

**Objetivo**: Versionado y publicaci√≥n del proyecto como repositorio open-source

**Comandos ejecutados**:

1. **Cancelaci√≥n del job Dataflow**:

   ```bash
   gcloud dataflow jobs cancel beamapp-ashramsatcitananda-1217173344-235534-vzxudzud \
       --region=us-central1

   ```

2. **Inicializaci√≥n de Git**:

   ```bash
   git init
   git add .
   git commit -m "feat: Complete streaming serverless pipeline project..."

   ```

3. **Configuraci√≥n de rama y remoto**:

   ```bash
   git branch -M main
   git remote add origin https://github.com/edushuaia/streaming-serverless-pipeline.git

   ```

4. **Push inicial**:

   ```bash
   git push -u origin main

   ```

   **Resultado**: 39 objetos, 2.22 MiB transferidos

5. **Commits adicionales**:
   - Screenshots y gu√≠a de captura
   - Mejoras visuales (zoom, badges, bot√≥n GitHub)
   - Enfoque educativo cient√≠fico-tecnol√≥gico

**Repositorio final**: <https://github.com/Edushuaia/streaming-serverless-pipeline>

**Resultado**: Proyecto completo publicado en GitHub.

---

### **Fase 13: Enfoque Educativo Cient√≠fico-Tecnol√≥gico**

**Objetivo**: Reposicionar el proyecto con valor educativo para comunidad cient√≠fica

**Cambios implementados**:

1. **Portada LinkedIn** (`linkedin-cover.html`):
   - Badge: "üéì Proyecto Educativo"
   - Subt√≠tulo: "Investigaci√≥n en Procesamiento de Datos Cient√≠ficos"
   - Texto enfocado en aplicaciones cient√≠ficas

2. **Sitio web** (`index.html`):
   - T√≠tulo con emoji educativo: üéì
   - Contexto cient√≠fico-tecnol√≥gico
   - Aplicaciones: IoT, telescopios, meteorolog√≠a, aceleradores

3. **README.md**:
   - Secci√≥n "Contexto Educativo"
   - "Motivaci√≥n Cient√≠fico-Tecnol√≥gica"
   - Badge "Educational"
   - √ânfasis en replicabilidad acad√©mica

4. **P√°gina evidencias**:
   - Header actualizado: "Proyecto Educativo"

**Aplicaciones destacadas**:

- Procesamiento de telemetr√≠a espacial
- Monitoreo ambiental en tiempo real
- An√°lisis de datos experimentales
- Sistemas de alerta temprana
- Sensores IoT cient√≠ficos

**Texto LinkedIn actualizado**:

- Democratizaci√≥n del acceso a procesamiento avanzado
- Recurso educativo para estudiantes e investigadores
- C√≥digo abierto documentado para aprendizaje
- Arquitectura replicable para proyectos acad√©micos

**Resultado**: Proyecto reposicionado con valor educativo y cient√≠fico.

---

### **Fase 14: Material para LinkedIn**

**Objetivo**: Crear portada profesional y texto optimizado para publicaci√≥n en LinkedIn

**Archivo creado**: `linkedin-cover.html`

**Especificaciones t√©cnicas**:

- Dimensiones: 1200x627px (formato √≥ptimo LinkedIn)
- Dise√±o moderno con gradiente oscuro
- Componentes:
  - Badge "üéì Proyecto Educativo"
  - T√≠tulo destacado con gradiente
  - 4 tecnolog√≠as clave con iconos
  - Diagrama de flujo simplificado
  - 3 stats (23K+ mensajes, 14/14 tests, 100% serverless)
  - Badge GitHub con usuario

**Instrucciones incluidas**:

- 8 pasos detallados para publicar
- Texto completo para copiar/pegar
- Consejos de timing (Martes-Jueves, 8-10 AM o 5-6 PM)
- Tips de engagement

**Texto para LinkedIn** (adaptado cient√≠fico):

```text
üéì Proyecto Educativo: Pipeline de Streaming Serverless para Datos Cient√≠ficos

He desarrollado un proyecto educativo explorando arquitecturas serverless 
para el procesamiento de flujos de datos cient√≠ficos en tiempo real...

üî¨ Contexto Cient√≠fico-Tecnol√≥gico:
En entornos de investigaci√≥n cient√≠fica (sensores IoT, telescopios, 
aceleradores de part√≠culas, estaciones meteorol√≥gicas)...

üéØ Desaf√≠o Investigado:
¬øC√≥mo procesar flujos impredecibles de datos cient√≠ficos con baja latencia, 
sin infraestructura fija ni costos operativos elevados?

[... resto del texto ...]

#DataScience #CloudComputing #ScientificComputing #BigData #Research #IoT

```

**Resultado**: Material completo para publicaci√≥n profesional.

---

## üõ†Ô∏è Decisiones T√©cnicas Clave

### **1. Arquitectura Serverless**

**Decisi√≥n**: Usar servicios completamente gestionados de GCP

**Justificaci√≥n**:

- Zero infraestructura que mantener
- Autoescalado autom√°tico (0 ‚Üí N workers)
- Modelo pay-per-use (econ√≥mico para desarrollo/educaci√≥n)
- Alta disponibilidad sin configuraci√≥n

**Servicios elegidos**:

- **Cloud Pub/Sub**: Durabilidad garantizada, at-least-once delivery
- **Cloud Dataflow**: Motor Apache Beam gestionado, escalado el√°stico
- **BigQuery**: An√°lisis SQL optimizado, inserciones streaming eficientes

### **2. Apache Beam 2.70.0**

**Decisi√≥n**: Actualizar a versi√≥n 2.70.0 con soporte ARM64

**Justificaci√≥n**:

- Compatibilidad nativa con Apple Silicon
- √öltimas mejoras de rendimiento
- Correcciones de bugs
- Soporte mejorado para GCP

**Alternativas descartadas**:

- Versiones anteriores: Problemas de compatibilidad ARM64
- Usar emulaci√≥n x86_64: Menor rendimiento

### **3. Ventanas Temporales de 30 Segundos**

**Decisi√≥n**: Fixed Windows de 30 segundos

**Justificaci√≥n**:

- Balance entre latencia y agregaci√≥n significativa
- F√°cil de entender educativamente
- Apropiado para demostraci√≥n

**Alternativas consideradas**:

- Sliding Windows: Mayor complejidad, mismos resultados para demo
- Session Windows: Requiere datos con gaps naturales

### **4. Testing con pytest**

**Decisi√≥n**: Suite de tests con pytest y pytest-cov

**Justificaci√≥n**:

- Framework est√°ndar en Python
- F√°cil de usar y mantener
- Integraci√≥n con CI/CD
- Cobertura de c√≥digo medible

**Cobertura objetivo**: 60%+ (alcanzado: 66%)

### **5. Enfoque Educativo**

**Decisi√≥n**: Reposicionar como proyecto educativo cient√≠fico-tecnol√≥gico

**Justificaci√≥n**:

- Mayor impacto en comunidad acad√©mica
- Relevancia para investigaci√≥n cient√≠fica
- Aplicabilidad transversal (IoT, telescopios, meteorolog√≠a)
- C√≥digo abierto para aprendizaje

**Beneficios**:

- Atractivo para reclutadores en investigaci√≥n
- Potencial para colaboraciones acad√©micas
- Valor como recurso educativo

---

## üìä M√©tricas del Proyecto

### **C√≥digo**

| M√©trica | Valor |
| --------- | ------- |
| Archivos Python | 5 principales |
| L√≠neas de c√≥digo | ~2,500 (estimado) |
| Tests unitarios | 14 |
| Cobertura | 66% |
| Archivos HTML | 6 |
| Archivos Markdown | 6 |
| L√≠neas CSS | ~800 |
| L√≠neas JavaScript | ~600 |

### **Infraestructura GCP**

| Recurso | Detalles |
| --------- | ---------- |
| Pub/Sub Topic | `transactions-topic` |
| Pub/Sub Subscription | `dataflow-subscription` |
| BigQuery Dataset | `streaming_data_warehouse_v2` |
| BigQuery Table | `transaction_aggregates` (particionada) |
| Cloud Storage Bucket | `streaming-serverless-dataflow-staging` |
| Dataflow Jobs | 1 ejecutado (cancelado) |
| Mensajes procesados | 23,360+ |

### **Sitio Web**

| Elemento | Cantidad |
| ---------- | ---------- |
| P√°ginas HTML | 6 (index, evidencias, 4 tecnolog√≠as) |
| Preguntas quiz | 40 |
| Screenshots evidencias | 9 |
| Badges tecnol√≥gicos | 8 animados |
| Secciones navegaci√≥n | 4 |

### **Documentaci√≥n**

| Archivo                  | L√≠neas       | Estado           |
| ------------------------ | ------------ | ---------------- |
| README.md                | 642          | ‚úÖ Completo      |
| ARCHITECTURE.md          | ~300         | ‚úÖ Linting OK    |
| TESTING.md               | ~150         | ‚úÖ Linting OK    |
| DEPLOYMENT.md            | ~250         | ‚úÖ Linting OK    |
| GUIA_CAPTURAS.md         | 391          | ‚úÖ Completo      |
| CAPTURAR_EVIDENCIAS.md   | 214          | ‚úÖ Completo      |
| HISTORIAL_DESARROLLO.md  | Este archivo | üîÑ Generando     |

### **GitHub**

| M√©trica          | Valor                 |
| ---------------- | --------------------- |
| Commits          | 5+                    |
| Branches         | 1 (main)              |
| Tama√±o repo      | ~3 MB                 |
| Archivos tracked | 39                    |
| Stars            | 0 (reci√©n publicado)  |

---

## üîß Problemas Resueltos

### **1. Error de Schema en BigQuery**

**Problema**:

```text
ERROR: Field window_start_time has type TIMESTAMP with mode REQUIRED but is used in a PARTITION BY clause. PARTITION BY fields must not have a REQUIRED mode.

```

**Causa**: Campo `window_start_time` ten√≠a modo `REQUIRED` incompatible con particionamiento.

**Soluci√≥n**:

```bash
# Antes
window_start_time:TIMESTAMP:REQUIRED

# Despu√©s
window_start_time:TIMESTAMP

```

### **2. Tipos de Datos No Reconocidos**

**Problema**:

```text
ERROR: Invalid type: INTEGER
ERROR: Invalid type: FLOAT

```

**Causa**: BigQuery requiere `INT64` y `FLOAT64` espec√≠ficamente.

**Soluci√≥n**:

```bash
# Cambios en setup_bigquery.sh
total_transactions:INTEGER  ‚Üí total_transactions:INT64
sum_amount:FLOAT            ‚Üí sum_amount:FLOAT64
avg_amount:FLOAT            ‚Üí avg_amount:FLOAT64
max_amount:FLOAT            ‚Üí max_amount:FLOAT64
min_amount:FLOAT            ‚Üí min_amount:FLOAT64

```

### **3. Apache Beam en Apple Silicon**

**Problema**: Instalaci√≥n de Apache Beam fallaba o usaba emulaci√≥n x86_64.

**Soluci√≥n**: Instalaci√≥n forzada en modo ARM64:

```bash
arch -arm64 python3 -m pip install --upgrade --force-reinstall apache-beam[gcp]==2.70.0

```

**Verificaci√≥n**:

```bash
file $(which python3)
# /usr/local/bin/python3: Mach-O universal binary with 2 architectures: [x86_64:Mach-O 64-bit executable x86_64] [arm64]

```

### **4. Push Rechazado en GitHub**

**Problema**:

```text
! [rejected]        main -> main (fetch first)
error: failed to push some refs

```

**Causa**: GitHub cre√≥ README.md autom√°ticamente en el repositorio remoto.

**Soluci√≥n**:

```bash
git pull origin main --rebase
git push origin main

```

### **5. Dataflow Job Ejecut√°ndose**

**Problema**: Job de Dataflow corriendo incurriendo en costos.

**Soluci√≥n**: Cancelaci√≥n manual:

```bash
gcloud dataflow jobs cancel beamapp-ashramsatcitananda-1217173344-235534-vzxudzud --region=us-central1

```

---

## üìÇ Estructura Final del Proyecto

```text
streaming-serverless-pipeline/
‚îú‚îÄ‚îÄ .env                          # Configuraci√≥n (no versionado)
‚îú‚îÄ‚îÄ .gitignore                    # Exclusiones Git
‚îú‚îÄ‚îÄ README.md                     # Documentaci√≥n principal
‚îú‚îÄ‚îÄ ARCHITECTURE.md               # Arquitectura t√©cnica
‚îú‚îÄ‚îÄ TESTING.md                    # Gu√≠a de testing
‚îú‚îÄ‚îÄ DEPLOYMENT.md                 # Despliegue en GCP
‚îú‚îÄ‚îÄ GUIA_CAPTURAS.md             # Gu√≠a paso a paso
‚îú‚îÄ‚îÄ CAPTURAR_EVIDENCIAS.md       # Lista de screenshots
‚îú‚îÄ‚îÄ HISTORIAL_DESARROLLO.md      # Este archivo
‚îú‚îÄ‚îÄ requirements.txt              # Dependencias Python
‚îú‚îÄ‚îÄ config.py                     # Configuraci√≥n centralizada
‚îú‚îÄ‚îÄ logging_config.py            # Configuraci√≥n de logging
‚îú‚îÄ‚îÄ dataflow_pipeline.py         # Pipeline principal
‚îú‚îÄ‚îÄ publisher_simulator.py       # Publicador de mensajes
‚îú‚îÄ‚îÄ setup_bigquery.sh            # Script de setup BigQuery
‚îú‚îÄ‚îÄ linkedin-cover.html          # Portada para LinkedIn
‚îú‚îÄ‚îÄ index.html                    # P√°gina principal
‚îú‚îÄ‚îÄ evidencias.html              # Galer√≠a de evidencias
‚îú‚îÄ‚îÄ pubsub.html                  # P√°gina Cloud Pub/Sub
‚îú‚îÄ‚îÄ dataflow.html                # P√°gina Cloud Dataflow
‚îú‚îÄ‚îÄ apachebeam.html              # P√°gina Apache Beam
‚îú‚îÄ‚îÄ bigquery.html                # P√°gina BigQuery
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ test_pipeline.py         # 14 tests unitarios
‚îú‚îÄ‚îÄ css/
‚îÇ   ‚îî‚îÄ‚îÄ style.css                # Estilos del sitio
‚îú‚îÄ‚îÄ js/
‚îÇ   ‚îú‚îÄ‚îÄ main.js                  # JavaScript general
‚îÇ   ‚îî‚îÄ‚îÄ quiz.js                  # Sistema de quiz (40 preguntas)
‚îî‚îÄ‚îÄ img/
    ‚îú‚îÄ‚îÄ architecture_diagram.png
    ‚îú‚îÄ‚îÄ dataflow_autoscaling.png
    ‚îú‚îÄ‚îÄ evidencia-01-pubsub.png
    ‚îú‚îÄ‚îÄ evidencia-02-bigquery.png
    ‚îú‚îÄ‚îÄ evidencia-03-storage.png
    ‚îú‚îÄ‚îÄ evidencia-04-dataflow-graph.png
    ‚îú‚îÄ‚îÄ evidencia-05-dataflow-metrics.png
    ‚îú‚îÄ‚îÄ evidencia-06-bigquery-results.png
    ‚îú‚îÄ‚îÄ evidencia-07-pubsub-metrics.png
    ‚îú‚îÄ‚îÄ evidencia-08-tests-coverage.png
    ‚îî‚îÄ‚îÄ evidencia-09-coverage-report.png

```

---

## üéì Comandos √ötiles Resumidos

### **Testing**

```bash
# Ejecutar todos los tests
pytest tests/ -v

# Con cobertura
pytest --cov=dataflow_pipeline --cov-report=term tests/ -v

# Reporte HTML
pytest --cov=dataflow_pipeline --cov-report=html tests/
open htmlcov/index.html

```

### **GCP**

```bash
# Configurar proyecto
gcloud config set project streaming-serverless-dataflow

# Habilitar APIs
gcloud services enable pubsub.googleapis.com bigquery.googleapis.com dataflow.googleapis.com

# Crear Pub/Sub
gcloud pubsub topics create transactions-topic
gcloud pubsub subscriptions create dataflow-subscription --topic=transactions-topic

# Crear BigQuery
bash setup_bigquery.sh

# Crear Storage
gsutil mb -l us-central1 gs://streaming-serverless-dataflow-staging

# Desplegar Dataflow
python dataflow_pipeline.py \
    --runner=DataflowRunner \
    --project=streaming-serverless-dataflow \
    --region=us-central1 \
    --temp_location=gs://streaming-serverless-dataflow-staging/temp

# Listar jobs
gcloud dataflow jobs list --region=us-central1

# Cancelar job
gcloud dataflow jobs cancel <JOB_ID> --region=us-central1

```

### **Publisher**

```bash
# Simular mensajes
python publisher_simulator.py

# Con tasa espec√≠fica
# (modificar rate en el c√≥digo)

```

### **Git**

```bash
# Inicializar y publicar
git init
git add .
git commit -m "mensaje"
git branch -M main
git remote add origin https://github.com/usuario/repo.git
git push -u origin main

# Actualizar
git add .
git commit -m "mensaje"
git push origin main

```

---

## üöÄ Pr√≥ximos Pasos Sugeridos

### **Mejoras T√©cnicas**

1. **CI/CD Pipeline**:
   - GitHub Actions para tests autom√°ticos
   - Despliegue autom√°tico en GCP
   - Validaci√≥n de linting en PRs

2. **Monitoreo Avanzado**:
   - Dashboards en Cloud Monitoring
   - Alertas personalizadas
   - Integraci√≥n con Cloud Logging

3. **Optimizaci√≥n de Costos**:
   - Configuraci√≥n de cuotas
   - Alertas de presupuesto
   - An√°lisis de uso

4. **Escalabilidad**:
   - Pruebas de carga
   - Optimizaci√≥n de ventanas
   - Tuning de workers

### **Mejoras Educativas**

1. **Contenido Adicional**:
   - Videos tutoriales
   - Workshops interactivos
   - Art√≠culos t√©cnicos

2. **Casos de Uso**:
   - Ejemplos con datos reales cient√≠ficos
   - Notebooks Jupyter explicativos
   - Comparativas de rendimiento

3. **Comunidad**:
   - Foro de discusi√≥n
   - Contribuciones open-source
   - Colaboraciones acad√©micas

### **Portfolio**

1. **LinkedIn**:
   - Publicar con portada profesional
   - Engagement en comentarios
   - Compartir en grupos relevantes

2. **Presentaciones**:
   - Slides t√©cnicas
   - Demos en vivo
   - Case studies

3. **Certificaciones**:
   - Google Cloud Professional Data Engineer
   - Apache Beam certifications

---

## üìö Recursos Adicionales

### **Documentaci√≥n Oficial**

- [Apache Beam](https://beam.apache.org/documentation/)
- [Cloud Dataflow](https://cloud.google.com/dataflow/docs)
- [Cloud Pub/Sub](https://cloud.google.com/pubsub/docs)
- [BigQuery](https://cloud.google.com/bigquery/docs)

### **Tutoriales Relacionados**

- [Beam Programming Guide](https://beam.apache.org/documentation/programming-guide/)
- [Dataflow Quickstart](https://cloud.google.com/dataflow/docs/quickstarts)
- [Streaming into BigQuery](https://cloud.google.com/bigquery/streaming-data-into-bigquery)

### **Comunidad**

- [Stack Overflow - apache-beam](https://stackoverflow.com/questions/tagged/apache-beam)
- [Google Cloud Community](https://www.googlecloudcommunity.com/)
- [GitHub Issues](https://github.com/Edushuaia/streaming-serverless-pipeline/issues)

---

## üéØ Conclusiones

Este proyecto demuestra c√≥mo construir un pipeline de streaming profesional, educativo y listo para producci√≥n utilizando arquitecturas serverless modernas. El proceso documentado aqu√≠ sirve como:

1. **Referencia t√©cnica** para implementaciones similares
2. **Gu√≠a educativa** para estudiantes y profesionales
3. **Caso de estudio** de buenas pr√°cticas en ingenier√≠a de datos
4. **Portfolio profesional** para oportunidades laborales
5. **Recurso comunitario** para la comunidad open-source

**Logros clave**:

- ‚úÖ Arquitectura serverless completa
- ‚úÖ C√≥digo production-ready con tests
- ‚úÖ Documentaci√≥n exhaustiva
- ‚úÖ Sitio web interactivo profesional
- ‚úÖ Enfoque educativo cient√≠fico-tecnol√≥gico
- ‚úÖ Publicado en GitHub
- ‚úÖ Preparado para LinkedIn

**Total de horas**: ~12 horas de desarrollo y documentaci√≥n  
**Complejidad**: Media-Alta  
**Valor educativo**: Alto  
**Aplicabilidad real**: Alta

---

### ¬© 2025 Eduardo Villena Lozano | Ingenier√≠a de Datos

**Repositorio**: <https://github.com/Edushuaia/streaming-serverless-pipeline>

---
