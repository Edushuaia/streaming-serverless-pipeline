<!DOCTYPE html>
<html lang="es">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="description" content="Cloud Dataflow: Motor de procesamiento serverless para transformaci√≥n de datos en tiempo real.">
        <meta name="keywords" content="Cloud Dataflow, GCP, Apache Beam, Autoescalado, Windowing, Streaming">
        <title>Detalle | Cloud Dataflow</title>
        <link rel="stylesheet" href="css/style.css">
    </head>
    <body>

        <header class="hero">
            <div class="container">
                <h1 class="project-title">Pipeline Serverless de Streaming en
                    GCP</h1>
                <p class="subtitle">An√°lisis de Transacciones en Tiempo Real
                    (Latencia Baja)</p>
            </div>
        </header>

        <nav class="tool-nav">
            <div class="container">
                <a href="index.html" class="nav-item"
                    data-tool="overview">Visi√≥n General</a>
                <a href="pubsub.html" class="nav-item" data-tool="pubsub">Cloud
                    Pub/Sub</a>
                <a href="dataflow.html" class="nav-item active"
                    data-tool="dataflow">Cloud Dataflow</a>
                <a href="bigquery.html" class="nav-item"
                    data-tool="bigquery">BigQuery</a>
                <a href="apachebeam.html" class="nav-item"
                    data-tool="apachebeam">Apache Beam (Python)</a>
            </div>
        </nav>

        <main class="container main-content">
            <section class="section tool-detail-content">
                <h2>Cloud Dataflow: Motor de Procesamiento Serverless</h2>
                <p>Cloud Dataflow es el servicio de Google Cloud para la
                    ejecuci√≥n de <em>pipelines</em> de procesamiento de datos
                    escalables y totalmente gestionadas. Se basa en el modelo de
                    programaci√≥n unificado <strong>Apache Beam</strong>, que permite tratar
                    el procesamiento <em>batch</em> y <em>streaming</em> con el mismo
                    c√≥digo.</p>

                <h3>Rol en el Proyecto: Procesamiento en Tiempo Real</h3>
                <p>Dataflow es el componente central que consume los mensajes
                    del Topic de Pub/Sub y aplica la l√≥gica de negocio antes de
                    escribir en BigQuery. Su naturaleza <em>serverless</em> garantiza
                    que el <em>pipeline</em> pueda manejar la carga sin intervenci√≥n
                    manual.</p>

                <h3>Conceptos Clave Aplicados</h3>

                <div class="component-list">
                    <ul>
                        <li>
                            <h4>Autoescalado y Serverless</h4>
                            <p>Dataflow gestiona autom√°ticamente los recursos
                                (m√°quinas virtuales/workers) y escala
                                horizontalmente seg√∫n la carga de datos que
                                recibe de Pub/Sub. Esto fue crucial para validar
                                la <strong>resiliencia</strong> ante picos simulados de
                                transacciones.</p>
                        </li>
                        <li>
                            <h4>Windowing (Ventanas de Tiempo)</h4>
                            <p>Permite agrupar elementos por tiempo para
                                realizar c√°lculos. Aplicamos una **Ventana Fija
                                (Fixed Window)** de 30 segundos, esencial para
                                transformar un flujo interminable de eventos
                                individuales en un resumen peri√≥dico de
                                ventas.</p>
                        </li>
                        <li>
                            <h4>Latencia del Watermark</h4>
                            <p>Monitoreamos constantemente el *Watermark* (Marca
                                de Agua) para asegurar que el retraso en el
                                procesamiento es m√≠nimo. Una baja latencia del
                                *Watermark* confirma que la *pipeline* est√°
                                procesando los datos eficientemente en tiempo
                                casi real.</p>
                        </li>
                    </ul>
                </div>

                <div class="info-box">
                    <h4 class="info-box-title">
                        <span class="info-box-icon">üì¶</span> Infraestructura: Cloud Storage
                    </h4>
                    <p class="info-box-description">
                        Aunque <strong>Cloud Storage no aparece en el flujo de datos principal</strong> (Pub/Sub ‚Üí Dataflow ‚Üí BigQuery), 
                        Dataflow lo utiliza internamente como infraestructura necesaria:
                    </p>
                    <ul class="info-box-list">
                        <li><strong>Staging Location</strong> (<code>gs://bucket/staging/</code>): Almacena el c√≥digo del pipeline y las dependencias Python</li>
                        <li><strong>Temp Location</strong> (<code>gs://bucket/temp/</code>): Guarda archivos de trabajo temporal durante las operaciones de shuffle y agregaci√≥n</li>
                        <li><strong>Distribuci√≥n de Workers</strong>: Los workers descargan el c√≥digo desde el bucket al iniciar</li>
                    </ul>
                    <p class="info-box-note">
                        üí° Los datos procesados <strong>NO</strong> se almacenan en Storage, van directamente de Pub/Sub a BigQuery v√≠a memoria.
                    </p>
                </div>

                <a href="https://cloud.google.com/dataflow" target="_blank" rel="noopener noreferrer"
                    class="official-link">Documentaci√≥n Oficial de Google Cloud
                    Dataflow</a>
            </section>

            <!-- Quiz de Certificaci√≥n -->
            <section class="section quiz-container">
                <h2 class="quiz-title">üìù Quiz de Certificaci√≥n: Cloud Dataflow</h2>
                <p class="quiz-intro">Pon a prueba tus conocimientos con preguntas tipo Professional Data Engineer</p>
                <div id="dataflowQuiz"></div>
            </section>
        </main>

        <footer>
            <p>&copy; 2025 Eduardo Villena Lozano | Ingenier√≠a de Datos</p>
        </footer>

        <script src="js/main.js"></script>
        <script src="js/quiz.js"></script>
        <script>
            // Preguntas espec√≠ficas de Cloud Dataflow para Professional Data Engineer
            const dataflowQuestions = [
                {
                    question: "Tu pipeline de Dataflow en streaming est√° experimentando altos costos. Los workers se escalan constantemente pero el throughput es bajo. ¬øCu√°l es la causa m√°s probable y la soluci√≥n?",
                    options: [
                        "Usar m√°s workers fijos en lugar de autoscaling",
                        "Aumentar el tama√±o de las m√°quinas (machine type)",
                        "Identificar y optimizar operaciones 'hot keys' (claves calientes)",
                        "Cambiar de streaming a batch processing"
                    ],
                    correct: 2,
                    explanation: "Los 'hot keys' son la causa m√°s com√∫n de bajo throughput en Dataflow. Ocurren cuando demasiados elementos tienen la misma clave en una operaci√≥n GroupByKey o Combine, creando un cuello de botella. La soluci√≥n incluye: redistribuir las claves con t√©cnicas como 'add random suffix', usar 'Combine.perKey' en lugar de GroupByKey cuando sea posible, o redise√±ar el esquema de particionamiento."
                },
                {
                    question: "¬øCu√°l es la diferencia principal entre 'Windowing' y 'Triggers' en Apache Beam/Dataflow?",
                    options: [
                        "Windowing define CU√ÅNDO agrupar eventos; Triggers definen CU√ÅNDO emitir resultados",
                        "Windowing es para batch; Triggers es para streaming",
                        "Windowing maneja datos tard√≠os; Triggers manejan datos a tiempo",
                        "Son lo mismo, solo diferente sintaxis"
                    ],
                    correct: 0,
                    explanation: "Windowing divide el flujo de datos en ventanas finitas basadas en timestamps (ej: ventanas de 5 minutos). Triggers determinan CU√ÅNDO se emiten los resultados de cada ventana: puede ser al final de la ventana, peri√≥dicamente, despu√©s de cierto n√∫mero de elementos, o combinaciones. Esta separaci√≥n de 'qu√©' y 'cu√°ndo' es fundamental en el modelo de Beam."
                },
                {
                    question: "Est√°s procesando datos de IoT con timestamps de eventos. Algunos dispositivos env√≠an datos con 10 minutos de retraso. ¬øQu√© configuraci√≥n de Dataflow debes ajustar?",
                    options: [
                        "Allowed lateness (latencia permitida) del watermark",
                        "Window size (tama√±o de ventana)",
                        "Number of workers",
                        "Processing time trigger"
                    ],
                    correct: 0,
                    explanation: "Debes configurar 'allowed lateness' para la ventana. Por defecto, cuando el watermark pasa el final de una ventana, esta se cierra y los datos tard√≠os se descartan. Con 'allowed lateness', puedes especificar cu√°nto tiempo adicional esperar para procesar datos tard√≠os. Ejemplo: .withAllowedLateness(Duration.standardMinutes(10)). Los resultados se actualizar√°n cada vez que lleguen datos tard√≠os dentro de este per√≠odo."
                },
                {
                    question: "¬øCu√°l es el prop√≥sito del 'Shuffle' en Dataflow y cu√°ndo se produce?",
                    options: [
                        "Distribuir datos aleatoriamente entre workers para balanceo de carga",
                        "Reorganizar datos por clave antes de operaciones como GroupByKey",
                        "Mezclar datos de m√∫ltiples fuentes en un solo stream",
                        "Cachear datos en disco para optimizar memoria"
                    ],
                    correct: 1,
                    explanation: "El 'Shuffle' es una operaci√≥n costosa que reorganiza datos por clave para que todos los elementos con la misma clave lleguen al mismo worker. Se produce autom√°ticamente antes de operaciones como GroupByKey, CoGroupByKey, y Combine. Es la operaci√≥n m√°s costosa en Dataflow (I/O intensivo). Para optimizar: minimiza GroupByKeys, usa Combine.perKey en lugar de GroupByKey + sum, y considera si realmente necesitas agrupar."
                },
                {
                    question: "Tu pipeline de streaming procesa transacciones financieras. Necesitas garantizar que cada transacci√≥n se procese exactamente una vez. ¬øQu√© debes implementar?",
                    options: [
                        "Usar Session Windows en lugar de Fixed Windows",
                        "Configurar 'exactly-once' processing con idempotent sinks",
                        "Aumentar el n√∫mero de workers para redundancia",
                        "Usar Global Windows con un solo worker"
                    ],
                    correct: 1,
                    explanation: "Para exactly-once processing necesitas: 1) Dataflow con exactly-once mode habilitado (usa checkpointing interno), 2) Sinks idempotentes (ej: BigQuery con insertId, Bigtable con timestamp, o implementar deduplicaci√≥n). Aunque Dataflow puede garantizar que la l√≥gica de transformaci√≥n se ejecute exactly-once, el sink debe ser idempotente para evitar duplicados en caso de reintento. Solo algunos sinks nativos soportan esto autom√°ticamente."
                },
                {
                    question: "¬øCu√°l es la diferencia entre 'Dataflow Shuffle' y 'Dataflow Streaming Engine'?",
                    options: [
                        "Shuffle procesa datos batch; Streaming Engine procesa datos streaming",
                        "Shuffle es la operaci√≥n de reorganizar datos; Streaming Engine externaliza estado y procesamiento fuera de workers",
                        "Son lo mismo con diferente nombre",
                        "Shuffle es m√°s caro pero m√°s r√°pido que Streaming Engine"
                    ],
                    correct: 1,
                    explanation: "SHUFFLE: Operaci√≥n de reorganizaci√≥n de datos por clave (costosa, I/O intensiva). STREAMING ENGINE: Arquitectura que externaliza el estado del pipeline y buffers fuera de los workers VM hacia el backend de Dataflow. BENEFICIOS de Streaming Engine: 1) Workers m√°s peque√±os (menos CPU/memoria), 2) Recuperaci√≥n m√°s r√°pida de fallos, 3) Mejor autoscaling, 4) Reduce costos. RECOMENDACI√ìN: Siempre habilita Streaming Engine para pipelines de streaming (flag --enable_streaming_engine)."
                },
                {
                    question: "Tu pipeline de Dataflow batch tarda 4 horas en procesar 10TB. ¬øCu√°l es la mejor estrategia para reducir el tiempo de ejecuci√≥n?",
                    options: [
                        "Aumentar el n√∫mero de workers m√°ximos en autoscaling",
                        "Usar m√°quinas con m√°s CPU y memoria",
                        "Identificar y eliminar shuffles innecesarios, usar Combine en lugar de GroupByKey",
                        "Dividir el job en m√∫ltiples pipelines m√°s peque√±os"
                    ],
                    correct: 2,
                    explanation: "La optimizaci√≥n M√ÅS EFECTIVA es eliminar shuffles innecesarios. Cada GroupByKey causa un shuffle (costoso). OPTIMIZACIONES: 1) Usa Combine.perKey en lugar de GroupByKey + aggregate, 2) Filtra/selecciona columnas ANTES de shuffles, 3) Usa Fusion para combinar operaciones, 4) Revisa el Dataflow UI - Execution Graph para identificar cuellos de botella. Aumentar workers/m√°quinas ayuda, pero si el problema es l√≥gica ineficiente, solo aumenta costos sin gran mejora."
                },
                {
                    question: "¬øCu√°ndo deber√≠as usar 'Session Windows' en lugar de 'Fixed Windows' o 'Sliding Windows'?",
                    options: [
                        "Cuando necesitas ventanas de tama√±o fijo y predecible",
                        "Para capturar r√°fagas de actividad con gaps de inactividad (ej: sesiones de usuario)",
                        "Cuando necesitas solapamiento entre ventanas",
                        "Solo en pipelines batch, no en streaming"
                    ],
                    correct: 1,
                    explanation: "SESSION WINDOWS agrupa eventos en sesiones basadas en gaps de inactividad. Ejemplo: eventos de usuario se agrupan en una sesi√≥n hasta que hay 30 minutos sin actividad, entonces se cierra la sesi√≥n. CASOS DE USO: an√°lisis de sesiones web, detecci√≥n de patrones de comportamiento, procesamiento de logs por sesi√≥n. Las ventanas son de TAMA√ëO DIN√ÅMICO. Configura el 'gap duration': window.Sessions.withGapDuration(Duration.minutes(30))."
                },
                {
                    question: "Tu pipeline de streaming tiene latencia de procesamiento de 5 minutos cuando el SLA requiere menos de 1 minuto. ¬øQu√© deber√≠as revisar primero?",
                    options: [
                        "El tama√±o de las ventanas (window size)",
                        "El watermark lag y allowed lateness",
                        "External service calls o shuffles bloqueantes en transformaciones",
                        "El n√∫mero de subscriptions en Pub/Sub"
                    ],
                    correct: 2,
                    explanation: "Revisa PRIMERO las transformaciones por: 1) Llamadas s√≠ncronas a servicios externos (APIs, databases) que bloquean, 2) Shuffles innecesarios (GroupByKey), 3) Operaciones costosas sin optimizar. USA: 1) Beam Metrics para identificar DoFns lentas, 2) Dataflow UI - Worker Logs para detectar llamadas lentas, 3) Asynchronous lookups o batching para external calls. El watermark lag afecta cu√°ndo se emiten resultados de ventanas, pero no la latencia de procesamiento de elementos individuales."
                },
                {
                    question: "¬øQu√© significa 'backpressure' en el contexto de Dataflow y c√≥mo se maneja?",
                    options: [
                        "Es cuando el pipeline procesa datos m√°s r√°pido que la fuente",
                        "Es cuando una etapa del pipeline es m√°s lenta que las anteriores, causando acumulaci√≥n",
                        "Es una configuraci√≥n manual que debes ajustar",
                        "Solo ocurre en pipelines batch, no en streaming"
                    ],
                    correct: 1,
                    explanation: "BACKPRESSURE ocurre cuando una stage es m√°s lenta que las anteriores (ej: escritura a BigQuery es lenta, pero transformaciones son r√°pidas), causando acumulaci√≥n en buffers. Dataflow MANEJA AUTOM√ÅTICAMENTE: 1) Reduce la velocidad de lectura de la fuente, 2) Incrementa autoscaling de workers si es posible, 3) Buffers intermedios absorben r√°fagas temporales. INDICADORES: Monitorea 'System Lag' y 'Backlog' en Dataflow UI. Si persiste: optimiza la stage lenta, aumenta workers, o usa batching en escrituras."
                }
            ];

            document.addEventListener('DOMContentLoaded', () => {
                new Quiz('dataflowQuiz', dataflowQuestions);
            });
        </script>
    </body>
</html>