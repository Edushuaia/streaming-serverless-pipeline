<!DOCTYPE html>
<html lang="es">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="description" content="Cloud Dataflow: Motor de procesamiento serverless para transformaci칩n de datos en tiempo real.">
        <meta name="keywords" content="Cloud Dataflow, GCP, Apache Beam, Autoescalado, Windowing, Streaming">
        <title>Detalle | Cloud Dataflow</title>
        <link rel="stylesheet" href="css/style.css">
    </head>
    <body>

        <header class="hero">
            <div class="container">
                <h1 class="project-title">Pipeline Serverless de Streaming en
                    GCP</h1>
                <p class="subtitle">An치lisis de Transacciones en Tiempo Real
                    (Latencia Baja)</p>
            </div>
        </header>

        <nav class="tool-nav">
            <div class="container">
                <a href="index.html" class="nav-item"
                    data-tool="overview">Visi칩n General</a>
                <a href="pubsub.html" class="nav-item" data-tool="pubsub">Cloud
                    Pub/Sub</a>
                <a href="dataflow.html" class="nav-item active"
                    data-tool="dataflow">Cloud Dataflow</a>
                <a href="bigquery.html" class="nav-item"
                    data-tool="bigquery">BigQuery</a>
                <a href="apachebeam.html" class="nav-item"
                    data-tool="apachebeam">Apache Beam (Python)</a>
            </div>
        </nav>

        <main class="container main-content">
            <section class="section tool-detail-content">
                <h2>Cloud Dataflow: Motor de Procesamiento Serverless</h2>
                <p>Cloud Dataflow es el servicio de Google Cloud para la
                    ejecuci칩n de <em>pipelines</em> de procesamiento de datos
                    escalables y totalmente gestionadas. Se basa en el modelo de
                    programaci칩n unificado <strong>Apache Beam</strong>, que permite tratar
                    el procesamiento <em>batch</em> y <em>streaming</em> con el mismo
                    c칩digo.</p>

                <h3>Rol en el Proyecto: Procesamiento en Tiempo Real</h3>
                <p>Dataflow es el componente central que consume los mensajes
                    del Topic de Pub/Sub y aplica la l칩gica de negocio antes de
                    escribir en BigQuery. Su naturaleza <em>serverless</em> garantiza
                    que el <em>pipeline</em> pueda manejar la carga sin intervenci칩n
                    manual.</p>

                <h3>Conceptos Clave Aplicados</h3>

                <div class="component-list">
                    <ul>
                        <li>
                            <h4>Autoescalado y Serverless</h4>
                            <p>Dataflow gestiona autom치ticamente los recursos
                                (m치quinas virtuales/workers) y escala
                                horizontalmente seg칰n la carga de datos que
                                recibe de Pub/Sub. Esto fue crucial para validar
                                la <strong>resiliencia</strong> ante picos simulados de
                                transacciones.</p>
                        </li>
                        <li>
                            <h4>Windowing (Ventanas de Tiempo)</h4>
                            <p>Permite agrupar elementos por tiempo para
                                realizar c치lculos. Aplicamos una **Ventana Fija
                                (Fixed Window)** de 30 segundos, esencial para
                                transformar un flujo interminable de eventos
                                individuales en un resumen peri칩dico de
                                ventas.</p>
                        </li>
                        <li>
                            <h4>Latencia del Watermark</h4>
                            <p>Monitoreamos constantemente el *Watermark* (Marca
                                de Agua) para asegurar que el retraso en el
                                procesamiento es m칤nimo. Una baja latencia del
                                *Watermark* confirma que la *pipeline* est치
                                procesando los datos eficientemente en tiempo
                                casi real.</p>
                        </li>
                    </ul>
                </div>

                <a href="https://cloud.google.com/dataflow" target="_blank" rel="noopener noreferrer"
                    class="official-link">Documentaci칩n Oficial de Google Cloud
                    Dataflow</a>
            </section>

            <!-- Quiz de Certificaci칩n -->
            <section class="section quiz-container">
                <h2 class="quiz-title">游닇 Quiz de Certificaci칩n: Cloud Dataflow</h2>
                <p class="quiz-intro">Pon a prueba tus conocimientos con preguntas tipo Professional Data Engineer</p>
                <div id="dataflowQuiz"></div>
            </section>
        </main>

        <footer>
            <p>&copy; 2025 Eduardo Villena Lozano | Ingenier칤a de Datos</p>
        </footer>

        <script src="js/main.js"></script>
        <script src="js/quiz.js"></script>
        <script>
            // Preguntas espec칤ficas de Cloud Dataflow para Professional Data Engineer
            const dataflowQuestions = [
                {
                    question: "Tu pipeline de Dataflow en streaming est치 experimentando altos costos. Los workers se escalan constantemente pero el throughput es bajo. 쮺u치l es la causa m치s probable y la soluci칩n?",
                    options: [
                        "Usar m치s workers fijos en lugar de autoscaling",
                        "Aumentar el tama침o de las m치quinas (machine type)",
                        "Identificar y optimizar operaciones 'hot keys' (claves calientes)",
                        "Cambiar de streaming a batch processing"
                    ],
                    correct: 2,
                    explanation: "Los 'hot keys' son la causa m치s com칰n de bajo throughput en Dataflow. Ocurren cuando demasiados elementos tienen la misma clave en una operaci칩n GroupByKey o Combine, creando un cuello de botella. La soluci칩n incluye: redistribuir las claves con t칠cnicas como 'add random suffix', usar 'Combine.perKey' en lugar de GroupByKey cuando sea posible, o redise침ar el esquema de particionamiento."
                },
                {
                    question: "쮺u치l es la diferencia principal entre 'Windowing' y 'Triggers' en Apache Beam/Dataflow?",
                    options: [
                        "Windowing define CU츼NDO agrupar eventos; Triggers definen CU츼NDO emitir resultados",
                        "Windowing es para batch; Triggers es para streaming",
                        "Windowing maneja datos tard칤os; Triggers manejan datos a tiempo",
                        "Son lo mismo, solo diferente sintaxis"
                    ],
                    correct: 0,
                    explanation: "Windowing divide el flujo de datos en ventanas finitas basadas en timestamps (ej: ventanas de 5 minutos). Triggers determinan CU츼NDO se emiten los resultados de cada ventana: puede ser al final de la ventana, peri칩dicamente, despu칠s de cierto n칰mero de elementos, o combinaciones. Esta separaci칩n de 'qu칠' y 'cu치ndo' es fundamental en el modelo de Beam."
                },
                {
                    question: "Est치s procesando datos de IoT con timestamps de eventos. Algunos dispositivos env칤an datos con 10 minutos de retraso. 쯈u칠 configuraci칩n de Dataflow debes ajustar?",
                    options: [
                        "Allowed lateness (latencia permitida) del watermark",
                        "Window size (tama침o de ventana)",
                        "Number of workers",
                        "Processing time trigger"
                    ],
                    correct: 0,
                    explanation: "Debes configurar 'allowed lateness' para la ventana. Por defecto, cuando el watermark pasa el final de una ventana, esta se cierra y los datos tard칤os se descartan. Con 'allowed lateness', puedes especificar cu치nto tiempo adicional esperar para procesar datos tard칤os. Ejemplo: .withAllowedLateness(Duration.standardMinutes(10)). Los resultados se actualizar치n cada vez que lleguen datos tard칤os dentro de este per칤odo."
                },
                {
                    question: "쮺u치l es el prop칩sito del 'Shuffle' en Dataflow y cu치ndo se produce?",
                    options: [
                        "Distribuir datos aleatoriamente entre workers para balanceo de carga",
                        "Reorganizar datos por clave antes de operaciones como GroupByKey",
                        "Mezclar datos de m칰ltiples fuentes en un solo stream",
                        "Cachear datos en disco para optimizar memoria"
                    ],
                    correct: 1,
                    explanation: "El 'Shuffle' es una operaci칩n costosa que reorganiza datos por clave para que todos los elementos con la misma clave lleguen al mismo worker. Se produce autom치ticamente antes de operaciones como GroupByKey, CoGroupByKey, y Combine. Es la operaci칩n m치s costosa en Dataflow (I/O intensivo). Para optimizar: minimiza GroupByKeys, usa Combine.perKey en lugar de GroupByKey + sum, y considera si realmente necesitas agrupar."
                },
                {
                    question: "Tu pipeline de streaming procesa transacciones financieras. Necesitas garantizar que cada transacci칩n se procese exactamente una vez. 쯈u칠 debes implementar?",
                    options: [
                        "Usar Session Windows en lugar de Fixed Windows",
                        "Configurar 'exactly-once' processing con idempotent sinks",
                        "Aumentar el n칰mero de workers para redundancia",
                        "Usar Global Windows con un solo worker"
                    ],
                    correct: 1,
                    explanation: "Para exactly-once processing necesitas: 1) Dataflow con exactly-once mode habilitado (usa checkpointing interno), 2) Sinks idempotentes (ej: BigQuery con insertId, Bigtable con timestamp, o implementar deduplicaci칩n). Aunque Dataflow puede garantizar que la l칩gica de transformaci칩n se ejecute exactly-once, el sink debe ser idempotente para evitar duplicados en caso de reintento. Solo algunos sinks nativos soportan esto autom치ticamente."
                },
                {
                    question: "쮺u치l es la diferencia entre 'Dataflow Shuffle' y 'Dataflow Streaming Engine'?",
                    options: [
                        "Shuffle procesa datos batch; Streaming Engine procesa datos streaming",
                        "Shuffle es la operaci칩n de reorganizar datos; Streaming Engine externaliza estado y procesamiento fuera de workers",
                        "Son lo mismo con diferente nombre",
                        "Shuffle es m치s caro pero m치s r치pido que Streaming Engine"
                    ],
                    correct: 1,
                    explanation: "SHUFFLE: Operaci칩n de reorganizaci칩n de datos por clave (costosa, I/O intensiva). STREAMING ENGINE: Arquitectura que externaliza el estado del pipeline y buffers fuera de los workers VM hacia el backend de Dataflow. BENEFICIOS de Streaming Engine: 1) Workers m치s peque침os (menos CPU/memoria), 2) Recuperaci칩n m치s r치pida de fallos, 3) Mejor autoscaling, 4) Reduce costos. RECOMENDACI칍N: Siempre habilita Streaming Engine para pipelines de streaming (flag --enable_streaming_engine)."
                },
                {
                    question: "Tu pipeline de Dataflow batch tarda 4 horas en procesar 10TB. 쮺u치l es la mejor estrategia para reducir el tiempo de ejecuci칩n?",
                    options: [
                        "Aumentar el n칰mero de workers m치ximos en autoscaling",
                        "Usar m치quinas con m치s CPU y memoria",
                        "Identificar y eliminar shuffles innecesarios, usar Combine en lugar de GroupByKey",
                        "Dividir el job en m칰ltiples pipelines m치s peque침os"
                    ],
                    correct: 2,
                    explanation: "La optimizaci칩n M츼S EFECTIVA es eliminar shuffles innecesarios. Cada GroupByKey causa un shuffle (costoso). OPTIMIZACIONES: 1) Usa Combine.perKey en lugar de GroupByKey + aggregate, 2) Filtra/selecciona columnas ANTES de shuffles, 3) Usa Fusion para combinar operaciones, 4) Revisa el Dataflow UI - Execution Graph para identificar cuellos de botella. Aumentar workers/m치quinas ayuda, pero si el problema es l칩gica ineficiente, solo aumenta costos sin gran mejora."
                },
                {
                    question: "쮺u치ndo deber칤as usar 'Session Windows' en lugar de 'Fixed Windows' o 'Sliding Windows'?",
                    options: [
                        "Cuando necesitas ventanas de tama침o fijo y predecible",
                        "Para capturar r치fagas de actividad con gaps de inactividad (ej: sesiones de usuario)",
                        "Cuando necesitas solapamiento entre ventanas",
                        "Solo en pipelines batch, no en streaming"
                    ],
                    correct: 1,
                    explanation: "SESSION WINDOWS agrupa eventos en sesiones basadas en gaps de inactividad. Ejemplo: eventos de usuario se agrupan en una sesi칩n hasta que hay 30 minutos sin actividad, entonces se cierra la sesi칩n. CASOS DE USO: an치lisis de sesiones web, detecci칩n de patrones de comportamiento, procesamiento de logs por sesi칩n. Las ventanas son de TAMA칌O DIN츼MICO. Configura el 'gap duration': window.Sessions.withGapDuration(Duration.minutes(30))."
                },
                {
                    question: "Tu pipeline de streaming tiene latencia de procesamiento de 5 minutos cuando el SLA requiere menos de 1 minuto. 쯈u칠 deber칤as revisar primero?",
                    options: [
                        "El tama침o de las ventanas (window size)",
                        "El watermark lag y allowed lateness",
                        "External service calls o shuffles bloqueantes en transformaciones",
                        "El n칰mero de subscriptions en Pub/Sub"
                    ],
                    correct: 2,
                    explanation: "Revisa PRIMERO las transformaciones por: 1) Llamadas s칤ncronas a servicios externos (APIs, databases) que bloquean, 2) Shuffles innecesarios (GroupByKey), 3) Operaciones costosas sin optimizar. USA: 1) Beam Metrics para identificar DoFns lentas, 2) Dataflow UI - Worker Logs para detectar llamadas lentas, 3) Asynchronous lookups o batching para external calls. El watermark lag afecta cu치ndo se emiten resultados de ventanas, pero no la latencia de procesamiento de elementos individuales."
                },
                {
                    question: "쯈u칠 significa 'backpressure' en el contexto de Dataflow y c칩mo se maneja?",
                    options: [
                        "Es cuando el pipeline procesa datos m치s r치pido que la fuente",
                        "Es cuando una etapa del pipeline es m치s lenta que las anteriores, causando acumulaci칩n",
                        "Es una configuraci칩n manual que debes ajustar",
                        "Solo ocurre en pipelines batch, no en streaming"
                    ],
                    correct: 1,
                    explanation: "BACKPRESSURE ocurre cuando una stage es m치s lenta que las anteriores (ej: escritura a BigQuery es lenta, pero transformaciones son r치pidas), causando acumulaci칩n en buffers. Dataflow MANEJA AUTOM츼TICAMENTE: 1) Reduce la velocidad de lectura de la fuente, 2) Incrementa autoscaling de workers si es posible, 3) Buffers intermedios absorben r치fagas temporales. INDICADORES: Monitorea 'System Lag' y 'Backlog' en Dataflow UI. Si persiste: optimiza la stage lenta, aumenta workers, o usa batching en escrituras."
                }
            ];

            document.addEventListener('DOMContentLoaded', () => {
                new Quiz('dataflowQuiz', dataflowQuestions);
            });
        </script>
    </body>
</html>