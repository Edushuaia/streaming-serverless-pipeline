# ğŸ“¸ GuÃ­a de Captura de Evidencias

## Checklist de Screenshots

- [ ] 1. Cloud Pub/Sub Topic y SuscripciÃ³n
- [ ] 2. BigQuery Dataset y Tabla
- [ ] 3. Cloud Storage Bucket
- [ ] 4. Grafo del Pipeline Dataflow
- [ ] 5. MÃ©tricas del Job Dataflow
- [ ] 6. Datos Procesados en BigQuery
- [ ] 7. MÃ©tricas de Pub/Sub
- [ ] 8. Suite de Tests (Terminal)
- [ ] 9. Reporte de Cobertura HTML (Navegador)

---

## ğŸ—ï¸ INFRAESTRUCTURA (3 capturas GCP)

### 1ï¸âƒ£ Cloud Pub/Sub - `img/evidencia-01-pubsub.png`

**URL:** <https://console.cloud.google.com/cloudpubsub/topic/list?project=streaming-serverless-dataflow>

**QuÃ© capturar:**

- âœ… Lista de topics mostrando "transactions-topic"
- âœ… Click en el topic para ver detalles
- âœ… PestaÃ±a "SUBSCRIPTIONS" mostrando "dataflow-subscription"

---

### 2ï¸âƒ£ BigQuery Dataset - `img/evidencia-02-bigquery.png`

**URL:** <https://console.cloud.google.com/bigquery?project=streaming-serverless-dataflow>

**QuÃ© capturar:**

- âœ… Panel izquierdo mostrando dataset "streaming_data_warehouse_v2"
- âœ… Expande el dataset para mostrar tabla "transaction_aggregates"
- âœ… Click en la tabla para ver el schema con los campos:
  - `window_start_time` (TIMESTAMP)
  - `total_transactions` (INT64)
  - `sum_amount` (FLOAT64)
  - `avg_amount` (FLOAT64)
  - `max_amount` (FLOAT64)
  - `min_amount` (FLOAT64)

---

### 3ï¸âƒ£ Cloud Storage Bucket - `img/evidencia-03-storage.png`

**URL:** <https://console.cloud.google.com/storage/browser?project=streaming-serverless-dataflow>

**QuÃ© capturar:**

- âœ… Lista de buckets mostrando "streaming-serverless-dataflow-staging"
- âœ… Click en el bucket para ver el contenido (carpetas temp/ y staging/)
- âœ… InformaciÃ³n del bucket: regiÃ³n, clase de almacenamiento

---

## âš™ï¸ PIPELINE DATAFLOW (2 capturas GCP)

### 4ï¸âƒ£ Grafo del Pipeline - `img/evidencia-04-dataflow-graph.png`

**URL:** <https://console.cloud.google.com/dataflow/jobs?project=streaming-serverless-dataflow>

**QuÃ© capturar:**

- âœ… Lista de jobs de Dataflow
- âœ… Click en el Ãºltimo job ejecutado (beamapp-ashramsatcitananda-...)
- âœ… PestaÃ±a "JOB GRAPH" mostrando el flujo completo:
  - Read from Pub/Sub
  - Parse JSON
  - Fixed Windows
  - Combine per key
  - Format for BigQuery
  - Write to BigQuery
- âœ… AsegÃºrate de que se vea todo el grafo completo

---

### 5ï¸âƒ£ MÃ©tricas del Job - `img/evidencia-05-dataflow-metrics.png`

**Misma pÃ¡gina del job anterior**

**QuÃ© capturar:**

- âœ… PestaÃ±a "METRICS" o "JOB INFO"
- âœ… GrÃ¡ficas mostrando:
  - Elements added/processed
  - System lag / Data watermark lag
  - Throughput (elementos por segundo)
  - Workers activos
- âœ… InformaciÃ³n de tiempo de ejecuciÃ³n

---

## ğŸ“ˆ RESULTADOS (2 capturas GCP)

### 6ï¸âƒ£ Datos en BigQuery - `img/evidencia-06-bigquery-results.png`

**URL:** <https://console.cloud.google.com/bigquery?project=streaming-serverless-dataflow>

**QuÃ© capturar:**

âœ… Ejecuta esta query en el editor de BigQuery:

```sql
SELECT 
  window_start_time,
  total_transactions,
  sum_amount,
  avg_amount,
  max_amount,
  min_amount
FROM `streaming-serverless-dataflow.streaming_data_warehouse_v2.transaction_aggregates`
ORDER BY window_start_time DESC
LIMIT 10
```

- âœ… Captura los RESULTADOS mostrando filas de datos procesados
- âœ… AsegÃºrate de que se vean las agregaciones por ventanas de tiempo

---

### 7ï¸âƒ£ MÃ©tricas de Pub/Sub - `img/evidencia-07-pubsub-metrics.png`

**URL:** <https://console.cloud.google.com/cloudpubsub/topic/detail/transactions-topic?project=streaming-serverless-dataflow>

**QuÃ© capturar:**

- âœ… PestaÃ±a "METRICS" del topic
- âœ… GrÃ¡ficas mostrando:
  - Publish message operations
  - Publish requests
  - Message sizes
  - Throughput a lo largo del tiempo
- âœ… Detalles de mensajes publicados y consumidos

---

## ğŸ§ª TESTING (2 capturas LOCALES)

### 8ï¸âƒ£ Suite de Tests - `img/evidencia-08-tests-coverage.png`

**Ejecuta en tu terminal:**

```bash
pytest --cov=dataflow_pipeline --cov-report=term tests/ -v
```

**QuÃ© capturar:**

- âœ… Output completo del terminal mostrando:
  - Los 14 tests ejecutÃ¡ndose con checkmarks âœ“
  - Resultado final "14 passed"
  - Tiempo de ejecuciÃ³n
  - Porcentaje de cobertura inicial

**TIP:** Haz la captura del terminal completo (`Cmd+Shift+3` en Mac) y recorta para que se vea la informaciÃ³n relevante.

---

### 9ï¸âƒ£ Reporte de Cobertura HTML - `img/evidencia-09-coverage-report.png`

**Ejecuta en tu terminal:**

```bash
pytest --cov=dataflow_pipeline --cov-report=html tests/
open htmlcov/index.html
```

**QuÃ© capturar:**

- âœ… PÃ¡gina HTML del reporte de cobertura en el navegador
- âœ… Debe mostrar:
  - Coverage general: 66%
  - Lista de archivos con sus porcentajes
  - `dataflow_pipeline.py` con su porcentaje especÃ­fico
  - LÃ­neas cubiertas vs totales

**TIP:** Es una captura del navegador mostrando el reporte HTML.

---

## ğŸ“ Notas Importantes

1. **Formato de imÃ¡genes:** PNG preferiblemente (mejor calidad para texto)
2. **ResoluciÃ³n:** MÃ­nimo 1280x720 para que se vean bien los detalles
3. **Nombres exactos:** Usa exactamente los nombres especificados (evidencia-01 a evidencia-09)
4. **UbicaciÃ³n:** Guarda todas en la carpeta `img/`
5. **Recorte:** Elimina informaciÃ³n sensible o innecesaria (barras de navegaciÃ³n, pestaÃ±as personales, etc.)

## ğŸš€ Una vez tengas los 9 screenshots

```bash
# Agregar las imÃ¡genes al repositorio
git add img/

# Crear commit
git commit -m "docs: Add project evidence screenshots

- Infrastructure screenshots (Pub/Sub, BigQuery, Storage)
- Dataflow pipeline visualization and metrics
- Query results and monitoring metrics
- Testing suite and coverage reports"

# Subir a GitHub
git push origin main
```

---

**âœ¨ Â¡Con esto tu proyecto estarÃ¡ 100% completo y listo para mostrar en tu portfolio!**
